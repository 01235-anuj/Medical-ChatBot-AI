# -*- coding: utf-8 -*-
"""Medical ChatBot AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x4urLM9JYckJQZVJ3cUcjLSmoDPGWinZ
"""

# Install dependencies

# Imports
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from transformers import pipeline
from langchain.llms import HuggingFacePipeline
from langchain.chains import RetrievalQA

# No !pip install here üö´



PDF_FILE = "Medical_Book.pdf"

# Load PDF
loader = PyPDFLoader(PDF_FILE)
documents = loader.load()

# Split text into chunks (smaller to avoid >512 token input)
text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=50)
docs = text_splitter.split_documents(documents)

from langchain_community.embeddings import HuggingFaceHubEmbeddings
from langchain_community.llms import HuggingFaceHub

# Requires Hugging Face API key in Streamlit secrets
embeddings = HuggingFaceHubEmbeddings(model="sentence-transformers/all-MiniLM-L6-v2")

llm = HuggingFaceHub(
    repo_id="google/flan-t5-large",
    model_kwargs={"temperature": 0.1, "max_length": 512}
)



# Wrap pipeline into LangChain
llm = HuggingFacePipeline(pipeline=generator)

qa = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=False   # ‚úÖ only one output now
)

def ask_bot(query):
    try:
        result = qa.run(query)  # works fine now
        return result + "\n\n‚ö†Ô∏è Disclaimer: This is AI from Gale Encyclopedia, not medical advice."
    except Exception as e:
        return f"‚ö†Ô∏è Error: {str(e)}"



st.title("üöÄ Medical ChatBot AI")
user_input = st.text_input("Enter your medical question:")
if st.button("Get Answer"):
    answer = ask_bot(user_input)
    st.write(answer)

